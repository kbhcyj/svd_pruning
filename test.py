"""
SVD ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸° ì‹œê°í™”

ë³¸ ì½”ë“œëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ ê²½ëŸ‰í™” ê¸°ìˆ ì¸ ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸°(Network Pruning)ì˜
ì›ë¦¬ë¥¼ SVD(íŠ¹ì´ê°’ ë¶„í•´)ë¥¼ í†µí•´ ê¸°í•˜í•™ì ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

ì£¼ìš” ê°œë…:
- ì™„ì „ ì—°ê²° ê³„ì¸µ(FC Layer)ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ SVDë¡œ ë¶„í•´
- ì‘ì€ íŠ¹ì´ê°’ì„ ì œê±°í•˜ì—¬ Low-Rank Approximation ìˆ˜í–‰
- ì´ëŠ” ëª¨ë¸ì˜ í‘œí˜„ ëŠ¥ë ¥(Rank)ì„ ê°ì†Œì‹œì¼œ íŒŒë¼ë¯¸í„°ë¥¼ ì¤„ì´ëŠ” ê²ƒê³¼ ë™ì¼
- 2ì°¨ì› ê³µê°„ì—ì„œì˜ ë³€í™˜ì„ ì‹œê°í™”í•˜ì—¬ ì •ë³´ ì†ì‹¤ì„ ì§ê´€ì ìœ¼ë¡œ ì´í•´
"""
import torch
import matplotlib.pyplot as plt
import numpy as np

def visualize_svd_pruning():
    # ============================================================
    # 1. ì…ë ¥ ë°ì´í„° ìƒì„±: ë‹¨ìœ„ ì› (Unit Circle)
    # ============================================================
    # ì‹ ê²½ë§ì˜ ì…ë ¥ ë¶„í¬ë¥¼ ëŒ€ë³€í•˜ê¸° ìœ„í•´ ëª¨ë“  ë°©í–¥ì„±ì„ ê°€ì§„ ë‹¨ìœ„ ë²¡í„°ë“¤ì„ ìƒì„±
    # 2ì°¨ì› ê³µê°„ì˜ ëª¨ë“  ë°©í–¥ì„ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§í•˜ì—¬ ê°€ì¤‘ì¹˜ í–‰ë ¬ì´
    # ì…ë ¥ì„ ì–´ë–»ê²Œ ë³€í˜•ì‹œí‚¤ëŠ”ì§€ ê´€ì°°í•  ìˆ˜ ìˆìŒ
    theta = np.linspace(0, 2*np.pi, 100)
    x = np.cos(theta)
    y = np.sin(theta)
    input_points = torch.tensor(np.stack([x, y], axis=1), dtype=torch.float32) # (100, 2)

    # ============================================================
    # 2. ì„ì˜ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ W ì„¤ì • (2x2 FC Layer)
    # ============================================================
    # ì´ í–‰ë ¬ì€ ì…ë ¥ ì°¨ì› 2 -> ì¶œë ¥ ì°¨ì› 2ì˜ ì™„ì „ ì—°ê²° ê³„ì¸µì„ ë‚˜íƒ€ëƒ„
    # ì‹¤ì œ ì‹ ê²½ë§ì—ì„œëŠ” ìˆ˜ì²œ~ìˆ˜ë§Œ ì°¨ì›ì¼ ìˆ˜ ìˆì§€ë§Œ, ì›ë¦¬ëŠ” ë™ì¼í•¨
    # 
    # ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸° ê´€ì :
    # - ì´ í–‰ë ¬ì˜ ë­í¬(Rank)ëŠ” 2 (í’€ ë­í¬)
    # - SVDë¡œ ë¶„í•´í•˜ë©´ 2ê°œì˜ íŠ¹ì´ê°’(Ïƒâ‚, Ïƒâ‚‚)ì„ ì–»ìŒ
    # - ì‘ì€ íŠ¹ì´ê°’(Ïƒâ‚‚)ì„ 0ìœ¼ë¡œ ë§Œë“¤ë©´ Rank-1 í–‰ë ¬ì´ ë¨
    # - ì´ëŠ” ëª¨ë¸ì˜ í‘œí˜„ë ¥ì„ ì˜ë„ì ìœ¼ë¡œ ê°ì†Œì‹œì¼œ íŒŒë¼ë¯¸í„°ë¥¼ ì••ì¶•í•˜ëŠ” ê²ƒ
    W = torch.tensor([[2.0, 1.0],
                      [1.5, 3.0]], dtype=torch.float32)

    # ============================================================
    # 3. ì›ë³¸ ì•„í•€ ë³€í™˜ (y = Wx) *í¸ì˜ìƒ biasëŠ” ìƒëµ
    # ============================================================
    # FC Layerì˜ ìˆœì „íŒŒ(Forward Pass): y = Wx + b
    # ê°€ì§€ì¹˜ê¸° ì „ì˜ ì›ë³¸ ëª¨ë¸ì´ ì…ë ¥ì„ ì–´ë–»ê²Œ ë³€í™˜í•˜ëŠ”ì§€ ê³„ì‚°
    # ë‹¨ìœ„ ì›ì´ íƒ€ì›(Ellipse)ìœ¼ë¡œ ë³€í˜•ë¨ -> 2ì°¨ì› ì •ë³´ ëª¨ë‘ ë³´ì¡´
    output_original = input_points @ W.T

    # ============================================================
    # 4. SVD ìˆ˜í–‰: W = U @ Î£ @ V^T
    # ============================================================
    # íŠ¹ì´ê°’ ë¶„í•´(SVD)ëŠ” í–‰ë ¬ì„ ë‹¤ìŒê³¼ ê°™ì´ ë¶„í•´:
    # W = U @ diag(S) @ V^T
    # 
    # í•´ì„:
    # - U: ì¶œë ¥ ê³µê°„ì˜ íšŒì „ (Left Singular Vectors)
    # - S: ê° ì£¼ì„±ë¶„ì˜ ì¤‘ìš”ë„ (Singular Values, íŠ¹ì´ê°’)
    # - V^T: ì…ë ¥ ê³µê°„ì˜ íšŒì „ (Right Singular Vectors)
    # 
    # ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸° ê´€ì :
    # - íŠ¹ì´ê°’ SëŠ” ê° "ì •ë³´ ì±„ë„"ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ëƒ„
    # - í° íŠ¹ì´ê°’: ì¶œë ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì¤‘ìš”í•œ ë°©í–¥
    # - ì‘ì€ íŠ¹ì´ê°’: ì˜í–¥ì´ ë¯¸ë¯¸í•œ ë°©í–¥ -> ê°€ì§€ì¹˜ê¸° ëŒ€ìƒ!
    U, S, Vh = torch.linalg.svd(W)
    
    print(f"Original Singular Values: {S}")
    print(f"  - Ïƒâ‚ (Major Axis): {S[0]:.4f}")
    print(f"  - Ïƒâ‚‚ (Minor Axis): {S[1]:.4f}")
    print(f"  - Ratio (Ïƒâ‚‚/Ïƒâ‚): {(S[1]/S[0]).item():.2%}")
    # ì˜ˆ: tensor([3.85..., 1.15...]) -> í° ì¶•ê³¼ ì‘ì€ ì¶•ì˜ ë¹„ìœ¨ í™•ì¸
    # ë¹„ìœ¨ì´ ì‘ì„ìˆ˜ë¡ ê°€ì§€ì¹˜ê¸° ì‹œ ì •ë³´ ì†ì‹¤ì´ ì ìŒ

    # ============================================================
    # 5. Low-Rank Approximation (Rank-1 ê·¼ì‚¬) - ê°€ì§€ì¹˜ê¸° ì‹œë®¬ë ˆì´ì…˜
    # ============================================================
    # ê°€ì¥ ì‘ì€ íŠ¹ì´ê°’ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ í–‰ë ¬ì˜ ë­í¬ë¥¼ ê°ì†Œì‹œí‚´
    # ì´ëŠ” ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸°ì˜ í•µì‹¬ ì•„ì´ë””ì–´:
    # "ì¤‘ìš”í•˜ì§€ ì•Šì€ ì—°ê²°(íŒŒë¼ë¯¸í„°)ì„ ì œê±°í•˜ì—¬ ëª¨ë¸ì„ ì••ì¶•"
    # 
    # Rank 2 -> Rank 1 ë³€í™˜:
    # - ì›ë˜: 2ê°œì˜ ë…ë¦½ì ì¸ ì¶œë ¥ ì°¨ì›
    # - ê°€ì§€ì¹˜ê¸° í›„: 1ê°œì˜ ì¶œë ¥ ì°¨ì›ìœ¼ë¡œ ì••ì¶• (1ì°¨ì› ì§ì„ )
    # 
    # ì‹¤ì œ ì‹ ê²½ë§ì—ì„œëŠ”:
    # - Rank 1000 -> Rank 100 ë“±ìœ¼ë¡œ ì••ì¶•
    # - íŒŒë¼ë¯¸í„° ìˆ˜: d_out Ã— d_in -> k(d_out + d_in) (k: ìœ ì§€í•  ë­í¬)
    # - ì˜ˆ: 1000Ã—1000 = 1M íŒŒë¼ë¯¸í„° -> 100(1000+1000) = 200K (80% ì••ì¶•)
    S_pruned = S.clone()
    S_pruned[-1] = 0  # ê°€ì¥ ì‘ì€ íŠ¹ì´ê°’ ì œê±° (Min Singular Value -> 0)
    
    # ê·¼ì‚¬ëœ í–‰ë ¬ W_approx ì¬êµ¬ì„±
    # W_approx = U @ diag(S_pruned) @ Vh
    # ì´ í–‰ë ¬ì€ ì›ë³¸ Wì˜ "ê°€ì§€ì¹˜ê¸°ëœ ë²„ì „"
    W_approx = U @ torch.diag(S_pruned) @ Vh
    
    # ì •ë³´ ì†ì‹¤ ì •ëŸ‰í™”
    info_retained = (S_pruned**2).sum() / (S**2).sum()
    print(f"\nInformation Retained: {info_retained.item():.2%}")
    print(f"Information Lost: {(1-info_retained).item():.2%}")

    # ============================================================
    # 6. ê°€ì§€ì¹˜ê¸°ëœ ëª¨ë¸ì˜ ì¶œë ¥ ê³„ì‚°
    # ============================================================
    # ì••ì¶•ëœ ê°€ì¤‘ì¹˜ í–‰ë ¬ W_approxë¥¼ ì‚¬ìš©í•œ ìˆœì „íŒŒ
    # ë‹¨ìœ„ ì›ì´ ì§ì„ (Line)ìœ¼ë¡œ ë³€í˜•ë¨ -> 1ì°¨ì›ìœ¼ë¡œ ì •ë³´ ì†ì‹¤
    output_pruned = input_points @ W_approx.T

    # ============================================================
    # 7. ì‹œê°í™”: ê°€ì§€ì¹˜ê¸°ì˜ ê¸°í•˜í•™ì  íš¨ê³¼ ë¹„êµ
    # ============================================================
    plt.figure(figsize=(15, 5))

    # Plot 1: ì…ë ¥ ê³µê°„ (ë‹¨ìœ„ ì›)
    # ì‹ ê²½ë§ì˜ ë‹¤ì–‘í•œ ì…ë ¥ì„ ëŒ€í‘œí•˜ëŠ” ë‹¨ìœ„ ë²¡í„°ë“¤
    plt.subplot(1, 3, 1)
    plt.scatter(input_points[:, 0], input_points[:, 1], c=theta, cmap='hsv', s=10)
    plt.title("1. Input Space (Unit Circle)\nëª¨ë“  ë°©í–¥ì˜ ì…ë ¥ ë²¡í„°", fontsize=11)
    plt.xlabel("xâ‚", fontsize=10)
    plt.ylabel("xâ‚‚", fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    plt.axhline(0, color='black', linewidth=0.5)
    plt.axvline(0, color='black', linewidth=0.5)

    # Plot 2: ì›ë³¸ FC Layer ì¶œë ¥ (ê°€ì§€ì¹˜ê¸° ì „)
    # Full Rank í–‰ë ¬: 2ì°¨ì› ì •ë³´ ëª¨ë‘ ë³´ì¡´
    plt.subplot(1, 3, 2)
    plt.scatter(output_original[:, 0], output_original[:, 1], c=theta, cmap='hsv', s=10)
    plt.title(f"2. Original Output (Ellipse)\nFull Rank=2 | Info={100:.1f}%", fontsize=11)
    plt.xlabel("yâ‚", fontsize=10)
    plt.ylabel("yâ‚‚", fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    plt.axhline(0, color='black', linewidth=0.5)
    plt.axvline(0, color='black', linewidth=0.5)
    
    # ì£¼ì¶•(Principal Axes) í‘œì‹œ
    axis_major = U[:, 0] * S[0]
    axis_minor = U[:, 1] * S[1]
    plt.arrow(0, 0, axis_major[0], axis_major[1], head_width=0.3, 
              head_length=0.2, fc='darkblue', ec='darkblue', linewidth=2, 
              label=f'Major Axis (Ïƒâ‚={S[0]:.2f})')
    plt.arrow(0, 0, axis_minor[0], axis_minor[1], head_width=0.2, 
              head_length=0.1, fc='darkred', ec='darkred', linewidth=2, 
              label=f'Minor Axis (Ïƒâ‚‚={S[1]:.2f})')
    plt.legend(fontsize=8, loc='upper right')

    # Plot 3: ê°€ì§€ì¹˜ê¸°ëœ FC Layer ì¶œë ¥ (Rank-1)
    # ì‘ì€ íŠ¹ì´ê°’ ì œê±° -> ì •ë³´ê°€ 1ì°¨ì›ìœ¼ë¡œ ì••ì¶•ë¨
    plt.subplot(1, 3, 3)
    plt.scatter(output_pruned[:, 0], output_pruned[:, 1], c=theta, cmap='hsv', s=10)
    info_pct = info_retained.item() * 100
    plt.title(f"3. Pruned Output (Line)\nRank=1 | Info={info_pct:.1f}%", fontsize=11)
    plt.xlabel("yâ‚", fontsize=10)
    plt.ylabel("yâ‚‚", fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    plt.axhline(0, color='black', linewidth=0.5)
    plt.axvline(0, color='black', linewidth=0.5)
    
    # ì œê±°ëœ ì¶• ì„¤ëª…
    plt.text(0, -2.5, "âš  Minor Axis Collapsed (ì •ë³´ ì†ì‹¤)", 
             ha='center', color='red', fontsize=10, weight='bold',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.suptitle("SVD ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸°: ê¸°í•˜í•™ì  í•´ì„", 
                 fontsize=14, weight='bold', y=1.02)
    plt.tight_layout()
    plt.savefig('svd_pruning_visualization.png', dpi=150, bbox_inches='tight')
    print("\n" + "="*60)
    print("âœ… Visualization saved to svd_pruning_visualization.png")
    print("="*60)
    # plt.show()


if __name__ == "__main__":
    print("="*60)
    print("ğŸš€ SVD ê¸°ë°˜ ë„¤íŠ¸ì›Œí¬ ê°€ì§€ì¹˜ê¸° ì‹œê°í™” ì‹œì‘")
    print("="*60)
    visualize_svd_pruning()
    print("\nğŸ’¡ ë” ìì„¸í•œ ì„¤ëª…ì€ NETWORK_PRUNING_GUIDE.mdë¥¼ ì°¸ê³ í•˜ì„¸ìš”!")
    print("="*60)